# LightRAG の軽量化効果が見えやすくなる条件の仮説

## 現状の分析

### 現在の問題点

1. **グラフノード数が少ない**

   - 現在の実装では約 7 ノード（Product: 2, Feature: 3, Policy: 2）のみ
   - データ量を 200 項目に増やしても、エンティティ抽出ロジックが限定的なためノード数が増えない

2. **接続性が低い**

   - 各ノードの平均次数（平均接続数）が低い
   - 探索パスが限定的で、差が出にくい

3. **質問の局所性が高い**
   - "Acme Search の機能は？"という質問では、関連ノードが少ない（5-7 ノード）
   - 局所探索でも全体探索でも同じ範囲を探索してしまう

## 効果が見えやすくなる条件の仮説

### 仮説 1: グラフノード数の閾値

**条件**: グラフノード数が **50-100 ノード以上**

**理由**:

- GraphRAG は全体グラフを探索するため、O(n²)的な計算量がかかる可能性
- LightRAG はクエリ依存の局所サブグラフ（`top_k`で制限）なので、ノード数が増えても探索範囲は一定
- **期待される差**:
  - GraphRAG: 20-30 ノード探索（全ノードの 20-30%）
  - LightRAG: 5-10 ノード探索（全ノードの 5-10%）

### 仮説 2: グラフの接続性（平均次数）

**条件**: 各ノードの平均次数が **3-5 以上**

**理由**:

- 接続性が高いと、GraphRAG は広範囲に探索する傾向がある
- LightRAG は`top_k`で制限されるため、接続性が高くても探索範囲は一定
- **期待される差**:
  - GraphRAG: 高接続性により 15-25 ノード探索
  - LightRAG: `top_k=4, depth=2`で 5-8 ノード探索

### 仮説 3: 探索深度の影響

**条件**: 多ホップ経路が必要な質問（depth=3-5 以上）

**理由**:

- GraphRAG: `max_depth`を大きくすると探索範囲が指数的に増加
- LightRAG: `depth`パラメータで制御できるが、`top_k`で最初の候補を絞るため増加が緩やか
- **期待される差**:
  - GraphRAG（`max_depth=5`）: 30-50 ノード探索
  - LightRAG（`top_k=4, depth=3`）: 8-12 ノード探索

### 仮説 4: 質問の多様性

**条件**: 局所的な質問とグローバルな質問の両方

**理由**:

- 局所的な質問（"Acme Search の機能は？"）: 差が小さい
- グローバルな質問（"すべての製品とその機能の関係"）: 差が大きくなる
- **期待される差**:
  - 局所的質問: 5-10 ノード vs 4-8 ノード（差: 1-2 ノード）
  - グローバル質問: 50-100 ノード vs 10-15 ノード（差: 40-85 ノード）

## 推奨されるテストデータセット

### 最小限の有効データセット構造

```
- ノード数: 50-100ノード
  - Product: 20-30ノード
  - Feature: 15-20ノード
  - Policy: 10-15ノード
  - その他（Company, Personなど）: 10-15ノード

- 平均次数: 3-5（各ノードが3-5個の他のノードと接続）

- 質問の種類:
  - 局所的: "Product X の機能は？"（期待: 5-10ノード探索）
  - 中規模: "Product X に関連するすべてのPolicyは？"（期待: 15-20ノード探索）
  - グローバル: "すべての製品と機能の関係"（期待: 50-100ノード探索）
```

### 現在の実装での課題

現在のエンティティ抽出ロジックは限定的：

- ハードコードされたエンティティ（Acme Search, Globex Graph, Semantic Index 等）のみ抽出
- 新しい製品（CloudBridge Platform, DataVault Pro 等）がデータに含まれていても抽出されない

**改善案**: NER（Named Entity Recognition）または LLM ベースのエンティティ抽出を実装する

## 結論

### 効果が見えやすくなる最小データ規模

**推奨**:

- **グラフノード数: 50-100 ノード**
- **平均次数: 3-5**
- **質問の多様性**: 局所的・中規模・グローバルの 3 種類

### 実装の改善が必要な点

1. **エンティティ抽出の拡張**: 現在のハードコード方式から、NER/LLM ベースの抽出へ
2. **グラフ構造の複雑化**: より多様な関係（DEPENDS_ON, COMPETES_WITH, USES など）を追加
3. **質問セットの拡張**: グローバルな質問を追加して、探索範囲の差を明確にする

### 実測可能な指標

- **探索ノード数の比率**: GraphRAG / LightRAG が 3:1 以上になることを目標
- **レイテンシの差**: データ量増加に伴い、LightRAG のレイテンシがより安定していることを確認
- **更新コスト**: 新規ノード追加時の再構築コストの差を測定

## 実験プロトコル（差を明確化するための最小構成）

### 目的

精度は同等と仮定し、**探索量とレイテンシの差**を可視化する。

### 固定前提

- ハードウェア：同一ノード（同一 CPU/GPU/メモリ）
- キャッシュ：**無効化**（初回実行のみ計測）。2 回目以降は別枠で参考値。
- プロンプト：同一テンプレ／同一温度
- 出力長：同一の `max_tokens` を設定
- 並列度：同一（GraphRAG/LightRAG ともに 1 並列で測定）

### 変数（グリッド）

- ノード数 `N`：**50 / 100 / 300 / 1000**
- 平均次数 `deg`：**1 / 3 / 5 / 8**（合成グラフで調整）
- 問合せタイプ：
  1. **局所**：「Product X の機能は？」
  2. **中規模**：「Product X に関連するすべての Policy は？」
  3. **グローバル**：「すべての製品と機能の関係を要約して」

### パラメータ

- GraphRAG：
  - `max_depth`：**2 / 3 / 5**（比較用）
  - `fanout`（1 ノードあたりの展開上限）：**5 / 10**
- LightRAG：
  - `top_k`：**4 固定**
  - `depth`：**2 固定**（多ホップは 3 も試行）

### 計測指標（ロガーで必須出力）

- `visited_nodes`：訪問ノード数
- `expanded_edges`：展開エッジ数
- `subgraph_build_ms`：サブグラフ構築時間
- `retrieval_ms`：検索/再ランキング時間
- `total_latency_ms`：合計レイテンシ
- `peak_memory_mb`：ピークメモリ（任意）
- `prompt_tokens` / `completion_tokens`：トークン利用（コスト目安）

> **成功基準（差が出たと判定）**
>
> - `visited_nodes` の比率（GraphRAG / LightRAG）**≧ 3**
> - `total_latency_ms` の比率（GraphRAG / LightRAG）**≧ 2**
> - 上記が **N ≥ 300**、かつ **deg ≥ 5** の条件で再現

### 可視化（必須）

- N を横軸に、**log スケール**の `visited_nodes` / `total_latency_ms` を縦軸にした折れ線グラフ（GraphRAG vs LightRAG）
- deg ごとに別プロット（もしくは凡例分割）
- 問合せタイプ別に 3 枚（局所/中規模/グローバル）

### 注意点（落とし穴）

- **キャッシュ/ウォームスタート**で差が消える：必ず初回を採用
- **非決定性**（LLM 呼び出しの遅延ブレ）：各条件 **n=5** 回の中央値で集計
- **実装差の影響**：GraphRAG の内部が中心性ベースの縮約探索をしている場合、N=100 程度では差が出にくい。**N=300–1000** で再検。
- **GPU/CPU 差**：どちらか片方が GPU 最適化されていると不公平。**同一設定**に固定。

### なぜこの設計で差が見えるか（直観モデル）

- 高次数 × 多ホップ条件では、GraphRAG はコミュニティを跨ぎやすく**探索が拡散**しやすい。
- LightRAG は `top_k` で**初期候補を絞り込む**ため、深さを増やしても**探索量が頭打ち**になりやすい。
